% Template for ICIP-2013 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{spconf,amsmath,graphicx}

% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}

\newcommand{\unit}[1]{\ensuremath{\, \mathrm{#1}}}

% Title.
% ------
\title{LOCATING PROJECTILE IMPACT LOCATIONS ON SHOOTING TARGETS}
%
% Single address.
% ---------------
\name{Brandon Nguyen}
\address{The University of Texas\\
         EE 371R, Electrical and Computer Engineering}

\begin{document}
%\ninept
%
\maketitle
%
\begin{abstract}
It is shown that by utilizing techniques such as scaling, filtering, and the
circle Hough transform that the points of impact on a target can be programatically located so that
more precise and sophisticated methods can be used to quickly calculate accuracy and precision metrics.
\end{abstract}
%
\begin{keywords}
Application, Circle Detection
\end{keywords}
%
\section{Background}
\label{sec:background}
A shooter requires feedback in the form of accuracy and precision metrics in order
to make adjustments to their zero (affected by accuracy) and see what their level
of performance is (precision).

Accuracy is determined by the "mean point of impact", which is the average location
of the population of points of impact. Shooters will typically visually estimate
the main point of impact since it is often impractical to find the coordinates
of each point of impact to perform the calculation.

Precision is a metric which has several different methods to determine.
The typical method used, due to its simplicity,  is "group size" where the distance
between the two furthest points of impact is determined. Shooters will typically visually
pick the two points and measure the distance using, if they have one, a ruler or
informal tools such as their fingers.

The two methods that shooters use above are inadequate for precisely determining
accuracy and precision. Visual estimation of the mean point of impact and two 
furthest points is imprecise and may lead to an inaccurate results. In addition,
the "group size" method used by shooters does not take into account outliers ("fliers")
which may result from an exceptional event such as a gust of wind or muscle spasm.

As noted above, it is impractical to perform other, more computationally precise methods.
Such methods require more time standing at a target which may inconvenience other shooters
if the targets are manually placed or cut into the shooter's own time at the range.

\section{Methods}
\label{sec:format}

Inputs to the system are the image of a target (or region of interest of an image to reduce
compute usage), a pixel to physical distance conversion for the image,
and the projectile diameter (caliber). Though ideally only a picture would
be required to locate the impact locations, knowledge of the conversion factor and projectile
diameter nearly eliminates image scaling issues.

OpenCV is a critical component of this project. OpenCV comes packaged with functions for
applying a multitude of filters, as well as the circle Hough transform which internally uses a
Canny edge dectector before running the accumulator.

With the knowledge of projectile diameter and a conversion factor for pixel to physical distance,
the image can be scaled so that impacts regardless of projectile diameter will be of the roughly
the same pixel radius. This reduces the complexity of the preprocessing steps and circle Hough
transform as now all circles will around the same size in pixels.
Let \(C \unit{\frac{pixels}{distance\ units}}\) be the conversion factor, \(N \unit{pixels}\)
be the normalized projectile radius in the image space, \(R \unit{distance\ units}\) be the 
actual radius of the projectile, \(S\) be the scaling factor for the image, \(D\) be 
the dimensions of the original image, and \(\bar{D}\) be the dimensions of the scaled image.

Thus:

\[S = \frac{N}{R * C}\]
\[\bar{D} = D * S\]

The image is initially converted to grayscale as intensity data and not color data is required
to pick out the structures of the impacts.
Preprocessing steps involving filtering are performed on the image. These steps are done
in context of the circle Hough transform being used to locate the impacts.
First, an even blur kernel is applied to the image in order to soften edges. This is so that
ragged edges of the impacts are smoothed out. Next, a Gaussian kernel is applied in order
to smooth out naturally occuring noise. Next, a median filter and bilateral filter are used in order
to create larger patches of the same intensity to prevent small edges from causing false circles.

% TODO

% References should be produced using the bibtex program from suitable
% BiBTeX files (here: strings, refs, manuals). The IEEEbib.bst bibliography
% style file from IEEE produces unsorted bibliography list.
% -------------------------------------------------------------------------
\bibliographystyle{IEEEbib}
\bibliography{strings,refs}

\end{document}
