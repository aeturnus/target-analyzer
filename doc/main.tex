% Template for ICIP-2013 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{spconf,amsmath,graphicx}

% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}

\newcommand{\unit}[1]{\ensuremath{\, \mathrm{#1}}}
\graphicspath{ {./images/} }

% Title.
% ------
\title{LOCATING PROJECTILE IMPACT LOCATIONS ON SHOOTING TARGETS}
%
% Single address.
% ---------------
\name{Brandon Nguyen}
\address{The University of Texas\\
         EE 371R, Electrical and Computer Engineering}

\begin{document}
%\ninept
%
\maketitle
%
\begin{abstract}
It is shown that by utilizing techniques such as scaling, filtering, and the
circle Hough transform that the points of impact on a target can be programatically located so that
more precise and sophisticated methods can be used to quickly calculate accuracy and precision metrics.
\end{abstract}
%
\begin{keywords}
Application, Circle Detection
\end{keywords}
%
\section{Background}
\label{sec:background}
A shooter requires feedback in the form of accuracy and precision metrics in order
to make adjustments to their zero (affected by accuracy) and see what their level
of performance is (precision).

Accuracy is determined by the "mean point of impact", which is the average location
of the population of points of impact. Shooters will typically visually estimate
the main point of impact since it is often impractical to find the coordinates
of each point of impact to perform the calculation.

Precision is a metric which has several different methods to determine.
The typical method used, due to its simplicity, is "group size" where the distance
between the two furthest points of impact is determined. Shooters will typically visually
pick the two points and measure the distance using, if they have one, a ruler or
informal tools such as their fingers.

The two methods that shooters use above are inadequate for precisely determining
accuracy and precision. Visual estimation of the mean point of impact and two 
furthest points is imprecise and may lead to an inaccurate results. In addition,
the "group size" method used by shooters does not take into account outliers ("fliers")
which may result from an exceptional event such as a gust of wind or muscle spasm.

As noted above, it is impractical to perform other, more computationally precise methods.
Such methods require more time standing at a target which may inconvenience other shooters
if the targets are manually placed or cut into the shooter's own time at the range.

\section{Tools and Materials}
\label{sec:tools}
OpenCV is a critical component of this project. OpenCV comes packaged with functions for
applying a multitude of filters, as well as the circle Hough transform which internally uses a
Canny edge detector before running the accumulator.

The Python bindings for OpenCV were used in order to quickly prototype the methods used.
An Android application is also being developed for mobile devices.
Due to potential marketability, the source of the Android application will not be available.
However, the Python prototype is publicly accessible.

The image data was collected personally. The targets used were of the "reactive" type, which
change color around where projectiles impact, NRA bulls-eye targets with a dark center coloration, and
white zeroing targets with grids to aid in zeroing sights. The calibers tested were .22 LR,
.223 Remington / 5.56x45 mm NATO, and 9x19 mm Parabellum.

\section{Methods}
\label{sec:methods}

\subsection{Overview}
\label{ssec:overview}
Inputs to the system are the image of a target (or region of interest of an image to reduce
compute usage), a pixel to physical distance conversion for the image,
and the projectile diameter (caliber). Though ideally only a picture would
be required to locate the impact locations, knowledge of the conversion factor and projectile
diameter nearly eliminates image scaling issues.

With the knowledge of projectile diameter and a conversion factor for pixel to physical distance,
the image can be scaled so that impacts regardless of projectile diameter will be of the roughly
the same pixel radius. This reduces the complexity of the preprocessing steps and circle Hough
transform as now all circles will around the same size in pixels.
Let \(C\ \unit{\frac{pixels}{distance\ units}}\) be the conversion factor, \(N\ \unit{pixels}\)
be the normalized projectile radius in the image space, \(R\ \unit{distance\ units}\) be the 
actual radius of the projectile, \(S\) be the scaling factor for the image, \(D\) be 
the dimensions of the original image, and \(\bar{D}\) be the dimensions of the scaled image.
Thus:

\[S = \frac{N}{R * C}\]

\[\bar{D} = D * S\]

The image is initially converted to grayscale as intensity data and not color data is required
to pick out the structures of the impacts.
Preprocessing steps involving filtering are performed on the image. These steps are done
in context of the circle Hough transform being used to locate the impacts.
First a Gaussian kernel is applied in order to eliminate out naturally occurring Gaussian noise.
Next, an even blur kernel is applied to the image in order to soften edges. This is so that
ragged edges of the impacts are smoothed out.
Next, a bilateral filter is used in order to amplify these smoothed out edges and provide 
more smoothing over noise.
Next, a median filter is used in order to create larger patches of the same intensity to 
prevent small edges from causing false circles.
Next, a sharpening filter is used to regain some edge definition.
As a final heuristically chosen step, 3 bilateral filters of the same \(\sigma{}\)s are used.
It was seen that this step helped reduced the number of false positives.

The circle Hough transform is then performed, resulting in the circles and their radii being returned.

\subsection{Parameters}
\label{ssec:parameters}
An issue still remains for the choosing of the parameters to use for the filters, their sizes, and
the circle Hough transform. Initially, parameters were manually tweaked and manually checked against
the images in the data-set.

The F-score was chosen as a metric for performance. For this, true positives
were defined as being able to successfully find an impact, false negatives were defined as
being unsuccessful to find an impact, and false positives were defined as finding an impact
where one doe snot exist.
The parameters were searched for by repeated calculating the F-score for the parameters and then
randomly adjusting their values in the positive, negative, or stationary directions by some
delta value.
At the end of the iterations, the parameters that resulted in the highest F-score was returned.

The parameters were: the Hough transform resolution, the Canny edge detector upper threshold, the minimum
distance scale, the minimum radius scale, the maximum radius scale, the accumulator scale, and the
sizes and \(\sigma{}\)s (when relevant) of the Gaussian, blur, bilateral, and median filters.
Note that for the "scale" parameters that by knowing what the diameters and radii of the circles
are beforehand (as part of the scaling step), values these parameters are scaling are functions
of the fixed pixel distance radius for all impacts.

\subsection{Implementation}
\label{ssec:implementation}

A Python prototype was created with an Android application in the works utilizing OpenCV.
The Python prototype takes as an argument the path to an image file, prompts
the user for the projectile diameter in inches (the United States shooting industry
still revolves around Imperial units), and then prompts the user to draw a line
on the original image as the pixel length to map to the real distance the user then inputs.
At this point the necessary scaling factor is calculated.
The user is then prompted to select a region of interest on the original target image.
That sub-image is then scaled, preprocessed, and has the circle Hough transform run on it.
The circles returned have their coordinates and radii in the scaled image space, so a
transformation step is performed to provide coordinates and radii in the dimensions of
the original image. These circles are then drawn onto an output image, with the mean
point of impact being calculated and depicted as a cross.

The Android application allows users to take photos or use one from their gallery. Similarly,
it prompts the user for projectile diameter, pixel-to-real-distance conversion factor, and
a region of interest on the image. It is in the Android application where careful management
of buffers is performed to keep the process performant on mobile devices:
there is very little delay when performing the circle Hough transform even on
images with high resolutions (e.g. 4608x3456).

Besides these two applications, additional helper applications were created. One application
was created to aid in creating a data-set, allowing users to click on a provided image
to provide the scaling factors, the region of interest, and where the holes are, with the application
printing out the data as a CSV entry. The other application was created to calculate the F-score
metric as well as run the parameter searching algorithm.

\section{Results}
\label{sec:results}

The data-set contains 33 targets from 18 different images. There were a total of 232 impacts
to identify. As a performance metric, the \(F_{0.5}\)-score was used. The \(0.5\) was chosen
since it penalizes for false positives more than it does for false negatives.
For this application, false positives are seen as more harmful than false negatives, since users
will be more confused about why random holes are being found as opposed to dismissing un-found
holes as the algorithm not working 100%.

Data was taken on the recall/sensitivity/true positive rate (TPR), the precision/positive predictive value (PPV),
and the \(F_{0.5}\)-score.

For reference:

\(tp\) = the number of true positives

\(fp\) = the number of false positives

\(fn\) = the number of false negatives

\[recall = \frac{tp}{tp + fn}\]
\[precision = \frac{tp}{tp + fp}\]
\[F_{\beta} = (1 + \beta{}^2) * \frac{precision * recall}{(\beta{}^2 * precision) + recall}\]
\(F_{0.5}\) is the case when \(\beta = 0.5\).

\begin{center}
    \begin{tabular}{ | l || l | l | l || l |}
    \hline
    Metric & Reactive & NRA & Sighting & Overall\\ \hline
    Recall      & 0.834 & 0.564 & 0.733 & 0.776\\ \hline
    Precision   & 0.986 & 0.846 & 0.957 & 0.963\\ \hline
    \(F_{0.5}\) & 0.951 & 0.769 & 0.902 & 0.918\\ \hline
    \end{tabular}
\end{center}

\subsection{Images}
\label{ssec:images}

\newcommand{\showsteps}[1] {
    \begin{figure}[htb]
    \begin{minipage}[b]{0.5\linewidth}
      \centering
      \centerline{\includegraphics[width=4.0cm]{out_1_#1}}
      \centerline{(1) Selected region}\medskip
    \end{minipage}%
    \begin{minipage}[b]{0.5\linewidth}
      \centering
      \centerline{\includegraphics[width=4.0cm]{out_2_#1}}
      \centerline{(2) Preprocessing performed}\medskip
    \end{minipage}
    
    \begin{minipage}[b]{0.5\linewidth}
      \centering
      \centerline{\includegraphics[width=4.0cm]{out_3_#1}}
      \centerline{(3) Canny edge map}\medskip
    \end{minipage}%
    \begin{minipage}[b]{0.5\linewidth}
      \centering
      \centerline{\includegraphics[width=4.0cm]{out_4_#1}}
      \centerline{(4) Resulting circles}\medskip
    \end{minipage}
    \caption{State of target#1.jpg through the process}
    \label{fig:res}
    \end{figure}
}

A variety of different targets were tested. Reported here are some of the interesting targets.

target0.jpg is the easiest target to analyze in the data-set. target0.jpg is a reactive type target,
where the colors around an impact will change from black to a bright color. This provides
plenty of contrast from the black surroundings and the hole. In addition, the entire image
focuses on just this one target.

target1.jpg provided the case of many impacts on a single reactive target.

target3.jpg is a NRA target, which has a dark center bulls-eye and concentric dark rings
on the light portions. Impacts in the dark bulls-eye have much less contrast and thus are
more difficult to pick out.

target8.jpg is a sighting target. Due to the thinner material of these targets compared
to the NRA and reactive targets, the holes have a different, more ragged shape.

target23.jpg is a small reactive target. The small reactive targets pose an issue
as the small concentric circles can induce false positives.

\showsteps{0}
\showsteps{1}
\showsteps{3}
\showsteps{8}
\showsteps{23}

% References should be produced using the bibtex program from suitable
% BiBTeX files (here: strings, refs, manuals). The IEEEbib.bst bibliography
% style file from IEEE produces unsorted bibliography list.
% -------------------------------------------------------------------------
\bibliographystyle{IEEEbib}
\bibliography{strings,refs}

\end{document}
